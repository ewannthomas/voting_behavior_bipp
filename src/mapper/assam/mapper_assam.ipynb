{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #install fuzzywuzzy\n",
    "!pip install fuzzywuzzy\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/.local/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import fuzzywuzzy as fw\n",
    "from fuzzywuzzy import process\n",
    "import openpyxl as op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/.local/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FID  OBJECTID  ST_CODE ST_NAME  DT_CODE   DIST_NAME  AC_NO      AC_NAME  \\\n",
      "60    60        14       18   ASSAM       14    TINSUKIA    126       Sadiya   \n",
      "61    61        14       18   ASSAM       13     DHEMAJI    114        Jonai   \n",
      "62    62        14       18   ASSAM       14    TINSUKIA    121       Chabua   \n",
      "63    63        13       18   ASSAM       15   DIBRUGARH    116    Dibrugarh   \n",
      "64    64        13       18   ASSAM       14    TINSUKIA    124   Margherita   \n",
      "..   ...       ...      ...     ...      ...         ...    ...          ...   \n",
      "188  188         2       18   ASSAM       21      CACHAR     11       Dholai   \n",
      "189  189         1       18   ASSAM       22   KARIMGANJ      1     Ratabari   \n",
      "190  190         1       18   ASSAM       22   KARIMGANJ      2  Patharkandi   \n",
      "191  191         1       18   ASSAM       23  HAILAKANDI      6   Hailakandi   \n",
      "192  192         1       18   ASSAM       23  HAILAKANDI      7  Katlicherra   \n",
      "\n",
      "     PC_NO    PC_NAME  PC_ID            STATUS  Shape_Leng  Shape_Area  \n",
      "60      14  LAKHIMPUR   1814  Pre delimitation    1.958132    0.121388  \n",
      "61      14  LAKHIMPUR   1814  Pre delimitation    2.353166    0.123464  \n",
      "62      14  LAKHIMPUR   1814  Pre delimitation    1.144645    0.036373  \n",
      "63      13  DIBRUGARH   1813  Pre delimitation    1.182483    0.041492  \n",
      "64      13  DIBRUGARH   1813  Pre delimitation    1.889304    0.073633  \n",
      "..     ...        ...    ...               ...         ...         ...  \n",
      "188      2    SILCHAR   1802  Pre delimitation    1.807111    0.080167  \n",
      "189      1  KARIMGANJ   1801  Pre delimitation    1.174894    0.045924  \n",
      "190      1  KARIMGANJ   1801  Pre delimitation    1.262824    0.051981  \n",
      "191      1  KARIMGANJ   1801  Pre delimitation    0.611350    0.019731  \n",
      "192      1  KARIMGANJ   1801  Pre delimitation    1.534567    0.072811  \n",
      "\n",
      "[133 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# odisha\n",
    "df1 = pd.read_excel('India_AC_shapefile.xlsx')\n",
    "df1.head()\n",
    "# read sheet 2 of goa masterlist\n",
    "df2 = pd.read_excel('assam_masterlist.xlsx', sheet_name=0)\n",
    "# df2 = pd.read_excel('goa_masterlist.xlsx')\n",
    "df2.rename(columns={'cleaned': 'cleaned'}, inplace=True)\n",
    "df2.rename(columns={'assembly constituency': 'AC_NAME'}, inplace=True)\n",
    "df2.rename(columns={'File Status': 'File Status'}, inplace=True)\n",
    "df2.rename(columns={'Error Comment': 'Error Comment'}, inplace=True)\n",
    "df2.rename(columns={'year': 'year'}, inplace=True)\n",
    "\n",
    "df2.head()\n",
    "\n",
    "\n",
    "\n",
    "def find_fuzzy_match(name, choices):\n",
    "    if not name:\n",
    "        return None\n",
    "    result = process.extractOne(name, choices)\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a mapping dictionary for rows in df2\n",
    "ac_name_mapping = {row['AC_NAME']: row for idx, row in df2.iterrows()}\n",
    "\n",
    "# Filter df1 for rows with ST_NAME \"GOA\" and map columns from df2 based on fuzzy matching\n",
    "df1_state = df1[df1['ST_NAME'] == 'ASSAM'].copy()  # Filter rows where ST_NAME is \"ODISHA\"\n",
    "print(df1_state)\n",
    "df1_state['Downloaded'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['Downloaded'])\n",
    "df1_state['year'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['year'])\n",
    "df1_state['Converted'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['Converted'])\n",
    "df1_state['cleaned'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['cleaned'])\n",
    "df1_state['File Status'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['File Status'])\n",
    "df1_state['Error Comment'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['Error Comment'])\n",
    "df1_state['election'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['election'])\n",
    "\n",
    "\n",
    "df1_state.to_excel('assam vs 2016.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/.local/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FID  OBJECTID  ST_CODE ST_NAME  DT_CODE   DIST_NAME  AC_NO      AC_NAME  \\\n",
      "60    60        14       18   ASSAM       14    TINSUKIA    126       Sadiya   \n",
      "61    61        14       18   ASSAM       13     DHEMAJI    114        Jonai   \n",
      "62    62        14       18   ASSAM       14    TINSUKIA    121       Chabua   \n",
      "63    63        13       18   ASSAM       15   DIBRUGARH    116    Dibrugarh   \n",
      "64    64        13       18   ASSAM       14    TINSUKIA    124   Margherita   \n",
      "..   ...       ...      ...     ...      ...         ...    ...          ...   \n",
      "188  188         2       18   ASSAM       21      CACHAR     11       Dholai   \n",
      "189  189         1       18   ASSAM       22   KARIMGANJ      1     Ratabari   \n",
      "190  190         1       18   ASSAM       22   KARIMGANJ      2  Patharkandi   \n",
      "191  191         1       18   ASSAM       23  HAILAKANDI      6   Hailakandi   \n",
      "192  192         1       18   ASSAM       23  HAILAKANDI      7  Katlicherra   \n",
      "\n",
      "     PC_NO    PC_NAME  PC_ID            STATUS  Shape_Leng  Shape_Area  \n",
      "60      14  LAKHIMPUR   1814  Pre delimitation    1.958132    0.121388  \n",
      "61      14  LAKHIMPUR   1814  Pre delimitation    2.353166    0.123464  \n",
      "62      14  LAKHIMPUR   1814  Pre delimitation    1.144645    0.036373  \n",
      "63      13  DIBRUGARH   1813  Pre delimitation    1.182483    0.041492  \n",
      "64      13  DIBRUGARH   1813  Pre delimitation    1.889304    0.073633  \n",
      "..     ...        ...    ...               ...         ...         ...  \n",
      "188      2    SILCHAR   1802  Pre delimitation    1.807111    0.080167  \n",
      "189      1  KARIMGANJ   1801  Pre delimitation    1.174894    0.045924  \n",
      "190      1  KARIMGANJ   1801  Pre delimitation    1.262824    0.051981  \n",
      "191      1  KARIMGANJ   1801  Pre delimitation    0.611350    0.019731  \n",
      "192      1  KARIMGANJ   1801  Pre delimitation    1.534567    0.072811  \n",
      "\n",
      "[133 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# odisha\n",
    "df1 = pd.read_excel('India_AC_shapefile.xlsx')\n",
    "df1.head()\n",
    "# read sheet 2 of goa masterlist\n",
    "df2 = pd.read_excel('assam_masterlist.xlsx', sheet_name=1)\n",
    "# df2 = pd.read_excel('goa_masterlist.xlsx')\n",
    "df2.rename(columns={'cleaned': 'cleaned'}, inplace=True)\n",
    "df2.rename(columns={'assembly constituency': 'AC_NAME'}, inplace=True)\n",
    "df2.rename(columns={'File Status': 'File Status'}, inplace=True)\n",
    "df2.rename(columns={'Error Comment': 'Error Comment'}, inplace=True)\n",
    "df2.rename(columns={'year': 'year'}, inplace=True)\n",
    "\n",
    "df2.head()\n",
    "\n",
    "\n",
    "\n",
    "def find_fuzzy_match(name, choices):\n",
    "    if not name:\n",
    "        return None\n",
    "    result = process.extractOne(name, choices)\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a mapping dictionary for rows in df2\n",
    "ac_name_mapping = {row['AC_NAME']: row for idx, row in df2.iterrows()}\n",
    "\n",
    "# Filter df1 for rows with ST_NAME \"GOA\" and map columns from df2 based on fuzzy matching\n",
    "df1_state = df1[df1['ST_NAME'] == 'ASSAM'].copy()  # Filter rows where ST_NAME is \"ODISHA\"\n",
    "print(df1_state)\n",
    "df1_state['Downloaded'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['Downloaded'])\n",
    "df1_state['year'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['year'])\n",
    "df1_state['Converted'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['Converted'])\n",
    "df1_state['cleaned'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['cleaned'])\n",
    "df1_state['File Status'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['File Status'])\n",
    "df1_state['Error Comment'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['Error Comment'])\n",
    "df1_state['election'] = df1_state['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df2['AC_NAME'])]['election'])\n",
    "\n",
    "\n",
    "df1_state.to_excel('ASSAM vs 2021.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/.local/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   election  year  AC no  State          AC_NAME  Downloaded  Converted  \\\n",
      "0     VS_be  2016     20  Assam  Baithalangso_st           0          0   \n",
      "1     VS_be  2017    113  Assam          dhemaji           1          1   \n",
      "2     VS_be  2019      1  Assam         Ratabari           1          1   \n",
      "3     VS_be  2019     74  Assam        Rangapara           1          1   \n",
      "4     VS_be  2019    106  Assam           Sonari           1          1   \n",
      "5     VS_be  2019     44  Assam            Jania           1          1   \n",
      "6     VS_be  2021     28  Assam       Gossaigaon           0          0   \n",
      "7     VS_be  2021     41  Assam       Bhabanipur           0          0   \n",
      "8     VS_be  2021     58  Assam         Tamulpur           0          0   \n",
      "9     VS_be  2021    107  Assam           Thowra           0          0   \n",
      "10    VS_be  2021    101  Assam          Mariani           0          0   \n",
      "11    VS_be  2022     99  Assam      Majuli (ST)           0          0   \n",
      "\n",
      "    Cleaned     File Status   Error Comment  Note  \n",
      "0         0  not downloaded             NaN   NaN  \n",
      "1         1    file cleaned  data available   NaN  \n",
      "2         1    file cleaned  data available   NaN  \n",
      "3         1    file cleaned  data available   NaN  \n",
      "4         1    file cleaned  data available   NaN  \n",
      "5         1    file cleaned  data available   NaN  \n",
      "6         0  not downloaded             NaN   NaN  \n",
      "7         0  not downloaded             NaN   NaN  \n",
      "8         0  not downloaded             NaN   NaN  \n",
      "9         0  not downloaded             NaN   NaN  \n",
      "10        0  not downloaded             NaN   NaN  \n",
      "11        0  not downloaded             NaN   NaN  \n",
      "     FID  OBJECTID  ST_CODE ST_NAME  DT_CODE   DIST_NAME  AC_NO      AC_NAME  \\\n",
      "60    60        14       18   ASSAM       14    TINSUKIA    126       Sadiya   \n",
      "61    61        14       18   ASSAM       13     DHEMAJI    114        Jonai   \n",
      "62    62        14       18   ASSAM       14    TINSUKIA    121       Chabua   \n",
      "63    63        13       18   ASSAM       15   DIBRUGARH    116    Dibrugarh   \n",
      "64    64        13       18   ASSAM       14    TINSUKIA    124   Margherita   \n",
      "..   ...       ...      ...     ...      ...         ...    ...          ...   \n",
      "188  188         2       18   ASSAM       21      CACHAR     11       Dholai   \n",
      "189  189         1       18   ASSAM       22   KARIMGANJ      1     Ratabari   \n",
      "190  190         1       18   ASSAM       22   KARIMGANJ      2  Patharkandi   \n",
      "191  191         1       18   ASSAM       23  HAILAKANDI      6   Hailakandi   \n",
      "192  192         1       18   ASSAM       23  HAILAKANDI      7  Katlicherra   \n",
      "\n",
      "     PC_NO    PC_NAME  PC_ID            STATUS  Shape_Leng  Shape_Area  \n",
      "60      14  LAKHIMPUR   1814  Pre delimitation    1.958132    0.121388  \n",
      "61      14  LAKHIMPUR   1814  Pre delimitation    2.353166    0.123464  \n",
      "62      14  LAKHIMPUR   1814  Pre delimitation    1.144645    0.036373  \n",
      "63      13  DIBRUGARH   1813  Pre delimitation    1.182483    0.041492  \n",
      "64      13  DIBRUGARH   1813  Pre delimitation    1.889304    0.073633  \n",
      "..     ...        ...    ...               ...         ...         ...  \n",
      "188      2    SILCHAR   1802  Pre delimitation    1.807111    0.080167  \n",
      "189      1  KARIMGANJ   1801  Pre delimitation    1.174894    0.045924  \n",
      "190      1  KARIMGANJ   1801  Pre delimitation    1.262824    0.051981  \n",
      "191      1  KARIMGANJ   1801  Pre delimitation    0.611350    0.019731  \n",
      "192      1  KARIMGANJ   1801  Pre delimitation    1.534567    0.072811  \n",
      "\n",
      "[133 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# goa for bye-election \n",
    "df1 = pd.read_excel('India_AC_shapefile.xlsx')\n",
    "df1.head()\n",
    "# read sheet 2 of goa masterlist\n",
    "df2 = pd.read_excel('assam_masterlist.xlsx', sheet_name=2)\n",
    "df2.rename(columns={'assembly constituency': 'AC_NAME'}, inplace=True)\n",
    "\n",
    "# df2 = pd.read_excel('goa_masterlist.xlsx')\n",
    "df2.head()\n",
    "print(df2)\n",
    "\n",
    "\n",
    "def find_fuzzy_match(name, choices):\n",
    "    if not name:\n",
    "        return None\n",
    "    result = process.extractOne(name, choices)\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a mapping dictionary for rows in df2\n",
    "ac_name_mapping = {row['AC_NAME']: row for idx, row in df1.iterrows()}\n",
    "\n",
    "# Filter df1 for rows with ST_NAME \"GOA\" and map columns from df2 based on fuzzy matching\n",
    "df1_state = df1[df1['ST_NAME'] == 'ASSAM'].copy()  # Filter rows where ST_NAME is \"GOA\"\n",
    "print(df1_state)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df2['FID'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['FID'])\n",
    "df2['OBJECTID'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['OBJECTID'])\n",
    "df2['ST_CODE'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['ST_CODE'])\n",
    "df2['ST_NAME'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['ST_NAME'])\n",
    "df2['DT_CODE'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['DT_CODE'])\n",
    "df2['DIST_NAME'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['DIST_NAME'])\n",
    "df2['AC_NO'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['AC_NO'])\n",
    "df2['PC_NO'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['PC_NO'])\n",
    "df2['PC_NAME'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['PC_NAME'])\n",
    "df2['PC_ID'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['PC_ID'])\n",
    "df2['STATUS'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['STATUS'])\n",
    "df2['Shape_Leng'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['Shape_Leng'])\n",
    "df2['Shape_Area'] = df2['AC_NAME'].apply(lambda x: ac_name_mapping[find_fuzzy_match(x, df1_state['AC_NAME'])]['Shape_Area'])\n",
    "\n",
    "# drop AC no\n",
    "df2.drop(['AC no'], axis=1, inplace=True)\n",
    "df2.drop(['State'], axis=1, inplace=True)\n",
    "\n",
    "# print(df1)\n",
    "df2.to_excel('ASSAM bye.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
